{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.What is conditional probability?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional probability is the probability of one event occurring with some relationship to one or more other events. For example:\n",
    "\n",
    "Event A is that it is raining outside, and it has a 0.3 (30%) chance of raining today.\n",
    "Event B is that you will need to go outside, and that has a probability of 0.5 (50%).\n",
    "A conditional probability would look at these two events in relationship with one another, such as the probability that it is both raining and you will need to go outside.\n",
    "\n",
    "The formula for conditional probability is:\n",
    "P(B|A) = P(A and B) / P(A)\n",
    "which you can also rewrite as:\n",
    "P(B|A) = P(A∩B) / P(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Discuss Bayes’s theorem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem, named after 18th-century British mathematician Thomas Bayes, is a mathematical formula for determining conditional probability. The theorem provides a way to revise existing predictions or theories (update probabilities) given new or additional evidence. In finance, Bayes' theorem can be used to rate the risk of lending money to potential borrowers.\n",
    "\n",
    "Bayes' theorem is also called Bayes' Rule or Bayes' Law and is the foundation of the field of Bayesian statistics.\n",
    "\n",
    "Bayes' Theorem allows you to update predicted probabilities of an event by incorporating new information.\n",
    "Bayes' Theorem was named after 18th century mathematician Thomas Bayes.\n",
    "It is often employed in finance in updating risk evaluation\n",
    "\n",
    "Bayes’ Theorem is a way of finding a probability when we know certain other probabilities.\n",
    "\n",
    "The formula is:\n",
    "\n",
    "P(A|B) =  P(A) P(B|A)/P(B) \n",
    "\n",
    "Which tells us:\t \thow often A happens given that B happens, written P(A|B),\n",
    "When we know:\t \thow often B happens given that A happens, written P(B|A)\n",
    " \t \tand how likely A is on its own, written P(A)\n",
    " \t \tand how likely B is on its own, written P(B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Explain the step by step working of Naïve Bayes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tLet’s consider that we have a binary classification problem i.e., we have two classes in our data as shown below.\n",
    "<img src=fig1.PNG width=300>\n",
    "2.\tNow suppose if we are given with a new data point, to which class does that point belong to?\n",
    "<img src=fig2.PNG width=300>\n",
    "3.\tThe formula for a point ‘X’ to belong in class1 can be written as:\n",
    "<img src=fig3.PNG width=300>\n",
    "Where the numbers represent the order in which we are going to calculate different probabilities.\n",
    "4.\tA similar formula can be utilised for class 2 as well.\n",
    "5.\tProbability of class 1 can be written as:\n",
    "$P(class1)=\\frac{Number of points in class1}{Total number of points}= \\frac {16}{26}=0.62$\n",
    "6.\tFor calculating the probability of X, we draw a circle around the new point and see how many points(excluding the new point) lie inside that circle.\n",
    "<img src=fig4.PNG width=300>\n",
    "\n",
    "The points inside the circle are considered to be similar points. \n",
    "$P(X)=\\frac{Number of similar observation}{Total Observations}=\\frac {3}{26}=0.12$\n",
    "7.\tNow, we need to calculate the probability of a point to be in the circle that we have made given that it’s of class 1.\n",
    "$P(X | Class1)= \\frac {Number of points in class 1 inside the circle}{Total number of points in class 1}=\\frac{1}{16}=0.06$\n",
    "8.\tWe can substitute all the values into the formula in step 3. We get:\n",
    "$P(Class1 | X)=\\frac{0.06*0.62}{0.12}=0.31$\n",
    "9.\tAnd if we calculate the probability that X belongs to Class2, we’ll get 0.69. It means that our point belongs to class 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.How is Naïve Bayes different from other classification algorithms?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a probabilistic algorithm that’s typically used for classification problems. Naive Bayes is simple, intuitive, and yet performs surprisingly well in many cases. For example, spam filters Email app uses are built on Naive Bayes.\n",
    "\n",
    "You can notice a major difference in the way in which the Naïve Bayes algorithm works form other classification algorithms. It does not first try to learn how to classify the points. It directly uses the label to identify the two separate classes and then it predicts the class to which the new point shall belong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.Why is the algorithm called Naïve Bayes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire algorithm is based on Bayes’s theorem to calculate probability. So, it also carries forward the assumptions for the Bayes’s theorem. But those assumptions(that the features are independent) might not always be true when implemented over a real-world dataset. So, those assumptions are considered Naïve and hence the name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.What is Gaussian Naïve Bayes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "\n",
    "When dealing with continuous data, a typical assumption is that the continuous values associated with each class are distributed according to a Gaussian distribution. Go back to the normal distribution lecture to review the formulas for the Gaussian/Normal Distribution.\n",
    "\n",
    "For example of using the Gaussian Distribution, suppose the training data contain a continuous attribute, x. We first segment the data by the class, and then compute the mean and variance of x in each class. Let  μ<sub>c</sub> be the mean of the values in x associated with class c, and let  σ<sup>2</sup><sub>c</sub> be the variance of the values in x associated with class c. Then, the probability distribution of some value given a class, p(x=v|c), can be computed by plugging v into the equation for a Normal distribution parameterized by μ<sub>c</sub> and  σ<sup>2</sup><sub>c</sub>. That is:\n",
    "\n",
    "$$p(x=v|c)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_c}}\\,e^{ -\\frac{(v-\\mu_c)^2}{2\\sigma^2_c} }$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.What are the advantages and disadvantages of Naïve Bayes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "Naive Bayes is extremely fast for both training and prediction as they not have to learn to create separate classes.\n",
    "Naive Bayes provides a direct probabilistic prediction.\n",
    "Naive Bayes is often easy to interpret.\n",
    "Naive Bayes has fewer (if any) parameters to tune\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "The algorithm assumes that the features are independent which is not always the scenario\n",
    "Zero Frequency i.e. if the category of any categorical variable is not seen in training data set even once then model assigns a zero probability to that category and then a prediction cannot be made."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
