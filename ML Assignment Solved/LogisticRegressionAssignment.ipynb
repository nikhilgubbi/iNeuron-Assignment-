{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tWhat is a classification problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is used to predict which class a data point is part of (discrete value).Classification gives the Prediction in Classified Form or we can say in YES/NO form.hence, Classification is used to categorize or classify the result\n",
    "\n",
    "Example: I have an unknown fruit that is yellow in color, 5.5 inches long, diameter of an inch, and density of X. What fruit is this? I would use classification for this kind of problem to classify it as a banana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tWhat is Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a statistical technique or a model in order to analyze a dataset and predict the binary outcome. The outcome has to be a binary outcome that is either\n",
    "zero or one or a yes or no.\n",
    "\n",
    "Example: I have a house with W rooms, X bathrooms, Y square-footage and Z lot-size. Based on other houses in the area that have recently sold, how much (dollar amount) can I sell my house for? I would use regression for this kind of problem.Regression gives the Prediction in the form of Values not in only YES/No or 1/0 format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tWhy is the Sigmoid function used for Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Function is the standard form of logistic function that ranges from 0 to 1”.\n",
    "\n",
    "1) The sigmoid function’s range is bounded between 0 and 1. Thus it’s useful in calculating the probability for the Logistic function. \n",
    "\n",
    "2) It’s derivative is easy to calculate than other functions which is useful during gradient descent calculation. 3) It is a simple way of introducing non-linearity to the model.\n",
    "Although there are other functions as well, which can be used, but sigmoid is the most common function used for logistic regression. We will talk about the rest of the functions in the neural network section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tWhat is the cost function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number. Depending on the problem Cost Function can be formed in many different ways. The purpose of Cost Function is to be either:\n",
    "Minimized - then returned value is usually called cost, loss or error. The goal is to find the values of model parameters for which Cost Function return as small number as possible.\n",
    "Maximized - then the value it yields is named a reward. The goal is to find values of model parameters for which returned number is as large as possible.\n",
    "\n",
    "The cost function equation is expressed as C(x)= FC + V(x), where C equals total production cost, FC is total fixed costs, V is variable cost and x is the number of units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tWhat is multiple Logistic Function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use multiple logistic regression when we have one nominal variable and two or more measurement variables, and we wanted to know how the measurement variables affect the nominal variable. we can use it to predict probabilities of the dependent nominal variable, or if we're careful,we can use it for suggestions about which independent variables have a major effect on the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tWhat is multilabel Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tHow does the Logistic Regression Algorithm learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning algorithm is how we search the set of possible hypotheses (hypothesis space $\\mathcal{H}$) for the best parameterization (in this case the weight vector ${\\bf w}$). This search is an optimization problem looking for the hypothesis that optimizes an error measure.\n",
    "\n",
    "There is no sophisticted, closed-form solution like least-squares linear, so we will use gradient descent instead. Specifically we will use batch gradient descent which calculates the gradient from all data points in the data set.\n",
    "\n",
    "Luckily, our \"cross-entropy\" error measure is convex so there is only one minimum. Thus the minimum we arrive at is the global minimum.\n",
    "\n",
    "To learn we're going to minimize the following error measure using batch gradient descent.\n",
    "\n",
    "$$\n",
    "e(h({\\bf x}_n), y_n) = \\ln \\left( 1+e^{-y_n \\; {\\bf w}^T {\\bf x}_n} \\right) \\\\\n",
    "E_\\text{in}({\\bf w}) = \\frac{1}{N} \\sum_{n=1}^{N} e(h({\\bf x}_n), y_n) = \\frac{1}{N} \\sum_{n=1}^{N} \\ln \\left( 1+e^{-y_n \\; {\\bf w}^T {\\bf x}_n} \\right)\n",
    "$$\n",
    "\n",
    "We'll need the derivative of the point loss function and possibly some abuse of notation.\n",
    "\n",
    "$$\n",
    "\\frac{d}{d{\\bf w}} e(h({\\bf x}_n), y_n)\n",
    "= \\frac{-y_n \\; {\\bf x}_n \\; e^{-y_n {\\bf w}^T {\\bf x}_n}}{1 + e^{-y_n {\\bf w}^T {\\bf x}_n}}\n",
    "= -\\frac{y_n \\; {\\bf x}_n}{1 + e^{y_n {\\bf w}^T {\\bf x}_n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.\tExplain the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm.\n",
    "\n",
    " True Positive(TP): A result that was predicted as positive by the classification model and also is positive\n",
    " True Negative(TN): A result that was predicted as negative by the classification model and also is negative\n",
    " False Positive(FP): A result that was predicted as positive by the classification model but actually is negative\n",
    " False Negative(FN): A result that was predicted as negative by the classification model but actually is positive.\n",
    "\n",
    "The Credibility of the model is based on how many correct predictions did the model do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tWhat is Accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "The mathematical formula is :\n",
    "\n",
    "   __Accuracy__= $ \\frac{ (TP+TN)}{(TP+TN+FP+FN)} $\n",
    "    \n",
    "Or, it can be said that it’s defined as the total number of correct classifications divided by the total number of classifications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.\tWhy there is a need for other metrics if ‘accuracy’ is already present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.\tWhat are Recall and Precision? How do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall or Sensitivity\n",
    "The mathematical formula is:\n",
    "\n",
    "   __Recall__= $ \\frac{ TP}{(TP+FN)} $\n",
    "\n",
    "Or, as the name suggests, it is a measure of: from the total number of positive results how many positives were correctly predicted by the model.\n",
    "\n",
    "It shows how relevant the model is, in terms of positive results only.\n",
    "\n",
    "Let’s suppose in the previous model, the model gave 50 correct predictions(TP) but failed to identify 200 cancer patients(FN). Recall in that case will be:\n",
    "\n",
    "Recall=$ \\frac {50}{(50+200)} $= 0.2 (The model was able to recall only 20% of the cancer patients)\n",
    "\n",
    "\n",
    "### Precision\n",
    "\n",
    "Precision is a measure of amongst all the positive predictions, how many of them were actually positive. Mathematically,\n",
    "\n",
    "Precision=$ \\frac {TP}{(TP+FP)} $\n",
    "\n",
    "Let’s suppose in the previous example, the model identified 50 people as cancer patients(TP) but also raised a  false alarm for 100 patients(FP). Hence,\n",
    "\n",
    "Precision=$ \\frac {50}{(50+100)} $=0.33 (The model only has a precision of 33%)\n",
    "\n",
    "\n",
    "\n",
    "As evident from the previous example, the model had a very high Accuracy but performed poorly in terms of Precision and Recall. So, necessarily Accuracy is not the metric to use for evaluating the model in this case.\n",
    "Imagine a scenario, where the requirement was that the model recalled all the defaulters who did not pay back the loan. Suppose there were 10 such defaulters and to recall those 10 defaulters, and the model gave you 20 results out of which only the 10 are the actual defaulters. Now, the recall of the model is 100%, but the precision goes down to 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.\tHow does the tradeoff between recall and precision work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Trade-off?\n",
    "\n",
    "<img src=\"tradeoff.PNG\" width=\"300\">\n",
    "\n",
    "As observed from the graph, with an increase in the Recall, there is a drop in Precision of the model.\n",
    "\n",
    "So the question is - what to go for? Precision or Recall?\n",
    "\n",
    "Well, the answer is: it depends on the business requirement.\n",
    "\n",
    "For example, if you are predicting cancer, you need a 100 % recall. But suppose you are predicting whether a person is innocent or not, you need 100% precision.\n",
    "\n",
    "Can we maximise both at the same time? No\n",
    "\n",
    "So, there is a need for a better metric then?\n",
    "\n",
    "Yes. And it’s called an _F1 Score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.\tExplain the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "\n",
    "From the previous examples, it is clear that we need a metric that considers both Precision and Recall for evaluating a model. One such metric is the F1 score.\n",
    "\n",
    "F1 score is defined as the harmonic mean of Precision and Recall. \n",
    "\n",
    "The mathematical formula is:\n",
    "        F1 score= $ \\frac {2*((Precision*Recall)}{(Precision+Recall))} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.\tWhat is specificity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity or True Negative Rate\n",
    "\n",
    "This represents how specific is the model while predicting the True Negatives.\n",
    "Mathematically,\n",
    "\n",
    "   Specificity=$ \\frac {TN}{(TN+FP)} $\n",
    "Or, it can be said that it quantifies the total number of negatives predicted by the model with respect to the total number of actual negative or non favorable outcomes.\n",
    "\n",
    "Similarly, False Positive rate can be defined as:  (1- specificity)\n",
    "Or,  $ \\frac {FP}{(TN+FP)} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.\tExplain the significance of ROC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the classification algorithms work on the concept of probability of occurrence of the possible outcomes. A probability value lies between 0 and 1. Zero means that there is no probability of occurrence and one means that the occurrence is certain.\n",
    "\n",
    "But while working with real-time data, it has been observed that we seldom get a perfect 0 or 1 value. Instead of that, we get different decimal values lying between 0 and 1. Now the question is if we are not getting binary probability values how are we actually determining the class in our classification problem?\n",
    "\n",
    "There comes the concept of Threshold. A threshold is set, any probability value below the threshold is a negative outcome, and anything more than the threshold is a favourable or the positive outcome. For Example, if the threshold is 0.5, any probability value below 0.5 means a negative or an unfavourable outcome and any value above 0.5 indicates a positive or favourable outcome. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.\tWhat is AUC, and when is it used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC(Area Under Curve)\n",
    "\n",
    "* It helps us to choose the best model amongst the models for which we have plotted the ROC curves\n",
    "* The best model is the one which encompasses the maximum area under it.\n",
    "* In the adjacent diagram, amongst the two curves, the model that resulted in the red one should be chosen as it clearly covers more area than the blue one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.\tExplain the steps for Heroku deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deployment to Heroku:**\n",
    "\n",
    "• After installing the Heroku CLI, Open a command prompt window and navigate to your project folder. \n",
    "• Type the command ‘heroku login’ to login to your heroku account as shown below:\n",
    "• After logging in to Heroku, enter the command ‘heroku create’ to create a heroku app\n",
    "• It will give you the URL of your Heroku app after successful creation.\n",
    "• Before deploying the code to the Heroku cloud, we need to commit the changes to the local git repository. \n",
    "• Type the command ‘git init to initialize a local git repository as shown below:\n",
    "• Enter the command ‘git status’ to see the uncommitted changes \n",
    "• Enter the command ‘git add .’ to add the uncommitted changes to the local repository. \n",
    "• Enter the command ‘git commit -am \"make it better\"’ to commit the changes to the local repository. \n",
    "• Enter the command ‘git push heroku master’ to push the code to the heroku cloud.\n",
    "• After deployment, heroku gives you the URL to hit the web API. \n",
    "• Once your application is deployed successfully, enter the command ‘heroku logs --tail’ to see the logs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.\tWhat difficulties did you face while deploying to Heroku?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was able to successfully deploy my regression model in to heroku cloud , Yes , 1 time i faced challenges in to commit the changes to the local repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
